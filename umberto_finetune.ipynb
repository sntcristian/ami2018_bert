{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ami_umberto2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2b4af0228b3c4fe8a927b8961c552bb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6ba7b94dccba428fa5f5a56b4929bde4",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4f396a2393c14a09a26ae34646a1b55f",
              "IPY_MODEL_db03b36fb00e4a08ac2abbb27df468ac"
            ]
          }
        },
        "6ba7b94dccba428fa5f5a56b4929bde4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4f396a2393c14a09a26ae34646a1b55f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_3902920922064b958253d5c48af5b867",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3de2912ed6e84fdf8115f1c80b6fc31a"
          }
        },
        "db03b36fb00e4a08ac2abbb27df468ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3f897fe2a5f74e69a7b74cd3dfb0aedd",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 508/508 [00:44&lt;00:00, 11.4B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4a6aaf3eb58c4e868ffc6a06a6052f19"
          }
        },
        "3902920922064b958253d5c48af5b867": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3de2912ed6e84fdf8115f1c80b6fc31a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3f897fe2a5f74e69a7b74cd3dfb0aedd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4a6aaf3eb58c4e868ffc6a06a6052f19": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "70ac4dea0bc34a2a9578d75dbe22bd26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_441cce1f48bd4fd2813a0780acea5368",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_49472c2a235647dfbf9a5def94dd612c",
              "IPY_MODEL_edd661a7fe99478ba89eab4076cd7c2d"
            ]
          }
        },
        "441cce1f48bd4fd2813a0780acea5368": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "49472c2a235647dfbf9a5def94dd612c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_55587a066d9848a79fab227b823db6af",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 793981,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 793981,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6645b54ffd274f7fba70ca35dfb85e03"
          }
        },
        "edd661a7fe99478ba89eab4076cd7c2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e1c0df85a7d74fca98597fcc0098775e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 794k/794k [00:32&lt;00:00, 24.3kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fbc038db007a460b9bea8a0868cda116"
          }
        },
        "55587a066d9848a79fab227b823db6af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6645b54ffd274f7fba70ca35dfb85e03": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e1c0df85a7d74fca98597fcc0098775e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fbc038db007a460b9bea8a0868cda116": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "538b620ed399444c801e4921578ae6ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_501ed35045a04d3b9424c0f0f4cf0a18",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_01bee5774aec4d1382f35a86a343075d",
              "IPY_MODEL_4762123613844dd9a789cb92a61da15d"
            ]
          }
        },
        "501ed35045a04d3b9424c0f0f4cf0a18": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "01bee5774aec4d1382f35a86a343075d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b18174fd114b4bcb8ff3c621bff01400",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 445031664,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 445031664,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fb041bc090e6471695396f49fa02b871"
          }
        },
        "4762123613844dd9a789cb92a61da15d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_859d729812164ae7b80b3a578b722a63",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 445M/445M [00:14&lt;00:00, 31.6MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_176bf078479944579654aa36e10a9137"
          }
        },
        "b18174fd114b4bcb8ff3c621bff01400": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fb041bc090e6471695396f49fa02b871": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "859d729812164ae7b80b3a578b722a63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "176bf078479944579654aa36e10a9137": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "89bd9e2608fb4d988cce42a0eca2e550": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_055d194d53444511acfc49b56372ee04",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b9fd8449660f482e92882b3cfe9be182",
              "IPY_MODEL_2fe1f09c00f14adab1f9d822a968824a"
            ]
          }
        },
        "055d194d53444511acfc49b56372ee04": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b9fd8449660f482e92882b3cfe9be182": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d00ea6d193354b2fac3555c5ab4db3a0",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3e0cf452ab7a44dfaca15ef6320f3008"
          }
        },
        "2fe1f09c00f14adab1f9d822a968824a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_dbc8e881b4f848ae879e993c3f984982",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 508/508 [00:00&lt;00:00, 5.69kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6f3d71d35c274b93b019341de2464612"
          }
        },
        "d00ea6d193354b2fac3555c5ab4db3a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3e0cf452ab7a44dfaca15ef6320f3008": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dbc8e881b4f848ae879e993c3f984982": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6f3d71d35c274b93b019341de2464612": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "328a0d0301944ac09b2d324090030b6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_92cdef78cf5b49de9453b751238133f7",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4080c5a6dd5a43f2916ce516f6719262",
              "IPY_MODEL_be3a3499febc43a9b54b39e40e73d53f"
            ]
          }
        },
        "92cdef78cf5b49de9453b751238133f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4080c5a6dd5a43f2916ce516f6719262": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_03c4f92441264f3f8c8d1a467d359381",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 793981,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 793981,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c0897c16347b428eaead9fa09f960c95"
          }
        },
        "be3a3499febc43a9b54b39e40e73d53f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b9c51f57a4df4e4fa94fc96d05715521",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 794k/794k [00:57&lt;00:00, 13.9kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6c16c474748e4fd9aa226b343922f7e5"
          }
        },
        "03c4f92441264f3f8c8d1a467d359381": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c0897c16347b428eaead9fa09f960c95": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b9c51f57a4df4e4fa94fc96d05715521": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6c16c474748e4fd9aa226b343922f7e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZAUsgYtKSUp"
      },
      "source": [
        "source_folder = '/content/drive/My Drive/ami_data/'\n",
        "destination_folder = '/content/drive/My Drive/ami_umberto2/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wgaDGY9KjX9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c008a2fd-00ba-462d-83d3-858a5a87d2fa"
      },
      "source": [
        "!pip install folium==0.2.1\n",
        "!pip install urllib3==1.25.4\n",
        "!pip install transformers==2.7.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting folium==0.2.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/72/dd/75ced7437bfa7cb9a88b96ee0177953062803c3b4cde411a97d98c35adaf/folium-0.2.1.tar.gz (69kB)\n",
            "\r\u001b[K     |████▊                           | 10kB 26.4MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 20kB 15.8MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 30kB 13.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 40kB 12.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 51kB 8.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 61kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 5.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: Jinja2 in /usr/local/lib/python3.6/dist-packages (from folium==0.2.1) (2.11.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2->folium==0.2.1) (1.1.1)\n",
            "Building wheels for collected packages: folium\n",
            "  Building wheel for folium (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for folium: filename=folium-0.2.1-cp36-none-any.whl size=79980 sha256=2852dc034e7f6500019cd2b4ef7f9c349da2cae9197dfcf5a0af6d644cf8bf0c\n",
            "  Stored in directory: /root/.cache/pip/wheels/b8/09/f0/52d2ef419c2aaf4fb149f92a33e0008bdce7ae816f0dd8f0c5\n",
            "Successfully built folium\n",
            "Installing collected packages: folium\n",
            "  Found existing installation: folium 0.8.3\n",
            "    Uninstalling folium-0.8.3:\n",
            "      Successfully uninstalled folium-0.8.3\n",
            "Successfully installed folium-0.2.1\n",
            "Collecting urllib3==1.25.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/0d/7777358f672a14b7ae0dfcd29f949f409f913e0578190d6bfa68eb55864b/urllib3-1.25.4-py2.py3-none-any.whl (125kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 9.1MB/s \n",
            "\u001b[?25hInstalling collected packages: urllib3\n",
            "  Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "Successfully installed urllib3-1.25.4\n",
            "Collecting transformers==2.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/37/ba/dda44bbf35b071441635708a3dd568a5ca6bf29f77389f7c7c6818ae9498/transformers-2.7.0-py3-none-any.whl (544kB)\n",
            "\u001b[K     |████████████████████████████████| 552kB 8.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers==2.7.0) (1.19.4)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers==2.7.0) (4.41.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==2.7.0) (2019.12.20)\n",
            "Collecting tokenizers==0.5.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/3f/73c881ea4723e43c1e9acf317cf407fab3a278daab3a69c98dcac511c04f/tokenizers-0.5.2-cp36-cp36m-manylinux1_x86_64.whl (3.7MB)\n",
            "\u001b[K     |████████████████████████████████| 3.7MB 14.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers==2.7.0) (3.0.12)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers==2.7.0) (0.8)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 25.9MB/s \n",
            "\u001b[?25hCollecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/2d/6d4ca4bef9a67070fa1cac508606328329152b1df10bdf31fb6e4e727894/sentencepiece-0.1.94-cp36-cp36m-manylinux2014_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 55.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==2.7.0) (2.23.0)\n",
            "Collecting boto3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c8/c6/b4d9547a493ac2837f296f4a004dff6e7136cf6750d181769b8a61d63813/boto3-1.16.50.tar.gz (100kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 12.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.7.0) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.7.0) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.7.0) (1.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.7.0) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.7.0) (1.25.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.7.0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.7.0) (3.0.4)\n",
            "Collecting botocore<1.20.0,>=1.19.50\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/16/19/113344007b2c1e4401f404f8e809f6151c00b164d78b164e4b688d30fc67/botocore-1.19.50-py2.py3-none-any.whl (7.2MB)\n",
            "\u001b[K     |████████████████████████████████| 7.2MB 55.2MB/s \n",
            "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading https://files.pythonhosted.org/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl\n",
            "Collecting s3transfer<0.4.0,>=0.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/69/79/e6afb3d8b0b4e96cefbdc690f741d7dd24547ff1f94240c997a26fa908d3/s3transfer-0.3.3-py2.py3-none-any.whl (69kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 3.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.20.0,>=1.19.50->boto3->transformers==2.7.0) (2.8.1)\n",
            "Building wheels for collected packages: sacremoses, boto3\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=80f6223dfa6f0917e8142c171c40fd6b462ac47788abd36bd3ee4ada4ba133ec\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "  Building wheel for boto3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for boto3: filename=boto3-1.16.50-py2.py3-none-any.whl size=128710 sha256=cd656f3aa2e44df9ed289cebba497b9ed7806e0e663ab8fc2354113050866b33\n",
            "  Stored in directory: /root/.cache/pip/wheels/4d/7a/70/33e66d82b7829099a8f9a9abbb669195cf10e4a7b25ff2bc2a\n",
            "Successfully built sacremoses boto3\n",
            "Installing collected packages: tokenizers, sacremoses, sentencepiece, jmespath, botocore, s3transfer, boto3, transformers\n",
            "Successfully installed boto3-1.16.50 botocore-1.19.50 jmespath-0.10.0 s3transfer-0.3.3 sacremoses-0.0.43 sentencepiece-0.1.94 tokenizers-0.5.2 transformers-2.7.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NU1PO209KkVV"
      },
      "source": [
        "# Libraries\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import torch\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9Z47b5XKpCp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f500e40-7fce-4fca-be4e-baa9f807e7e7"
      },
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ykmx2YaYKw_Z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117,
          "referenced_widgets": [
            "2b4af0228b3c4fe8a927b8961c552bb9",
            "6ba7b94dccba428fa5f5a56b4929bde4",
            "4f396a2393c14a09a26ae34646a1b55f",
            "db03b36fb00e4a08ac2abbb27df468ac",
            "3902920922064b958253d5c48af5b867",
            "3de2912ed6e84fdf8115f1c80b6fc31a",
            "3f897fe2a5f74e69a7b74cd3dfb0aedd",
            "4a6aaf3eb58c4e868ffc6a06a6052f19",
            "70ac4dea0bc34a2a9578d75dbe22bd26",
            "441cce1f48bd4fd2813a0780acea5368",
            "49472c2a235647dfbf9a5def94dd612c",
            "edd661a7fe99478ba89eab4076cd7c2d",
            "55587a066d9848a79fab227b823db6af",
            "6645b54ffd274f7fba70ca35dfb85e03",
            "e1c0df85a7d74fca98597fcc0098775e",
            "fbc038db007a460b9bea8a0868cda116"
          ]
        },
        "outputId": "fa77fbce-8377-4100-9008-61c30e78b798"
      },
      "source": [
        "from transformers import AutoTokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"Musixmatch/umberto-commoncrawl-cased-v1\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2b4af0228b3c4fe8a927b8961c552bb9",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=508.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "70ac4dea0bc34a2a9578d75dbe22bd26",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=793981.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "obDHVeSWLV-o",
        "outputId": "0d4f4430-a40e-4720-c39c-42bd978dfb0b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jr6E5I7PMFW0"
      },
      "source": [
        "# Load the dataset into a pandas dataframe.\n",
        "df = pd.read_csv(source_folder + \"it_training.tsv\", delimiter='\\t', header=0, names=['id', 'text', 'misoginy', 'category', 'target'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "soklJvV7Manu"
      },
      "source": [
        "sentences = df.text.values\n",
        "labels = df.misoginy.values\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GGTl3AOMeaH"
      },
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "    # `encode` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    encoded_sent = tokenizer.encode(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "\n",
        "                        # This function also supports truncation and conversion\n",
        "                        # to pytorch tensors, but we need to do padding, so we\n",
        "                        # can't use these features :( .\n",
        "                        #max_length = 128,          # Truncate all sentences.\n",
        "                        #return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.\n",
        "    input_ids.append(encoded_sent)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YsawvGFAMnAc",
        "outputId": "b6345dde-939a-4009-8f30-b7e506968d77"
      },
      "source": [
        "# We'll borrow the `pad_sequences` utility function to do this.\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Set the maximum sequence length.\n",
        "# I've chosen 64 somewhat arbitrarily. It's slightly smaller than the\n",
        "# maximum training sentence length of 92...\n",
        "MAX_LEN = 128\n",
        "print('\\nPadding/truncating all sentences to %d values...' % MAX_LEN)\n",
        "\n",
        "print('\\nPadding token: \"{:}\", ID: {:}'.format(tokenizer.pad_token, tokenizer.pad_token_id))\n",
        "\n",
        "# Pad our input tokens with value 0.\n",
        "# \"post\" indicates that we want to pad and truncate at the end of the sequence,\n",
        "# as opposed to the beginning.\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", \n",
        "                          value=1, truncating=\"post\", padding=\"post\")\n",
        "print('\\nDone.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Padding/truncating all sentences to 128 values...\n",
            "\n",
            "Padding token: \"<pad>\", ID: 1\n",
            "\n",
            "Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9mADPTKMwPv"
      },
      "source": [
        "# Create attention masks\n",
        "attention_masks = []\n",
        "\n",
        "# For each sentence...\n",
        "for sent in input_ids:\n",
        "    \n",
        "    # Create the attention mask.\n",
        "    #   - If a token ID is 0, then it's padding, set the mask to 0.\n",
        "    #   - If a token ID is > 0, then it's a real token, set the mask to 1.\n",
        "    att_mask = [int(token_id > 1) for token_id in sent]\n",
        "    \n",
        "    # Store the attention mask for this sentence.\n",
        "    attention_masks.append(att_mask)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRxSRquQNL0B"
      },
      "source": [
        "# Use train_test_split to split our data into train and validation sets for\n",
        "# training\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Use 90% for training and 10% for validation.\n",
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels, \n",
        "                                                            random_state=2018, test_size=0.1)\n",
        "# Do the same for the masks.\n",
        "train_masks, validation_masks, _, _ = train_test_split(attention_masks, labels,\n",
        "                                             random_state=2018, test_size=0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--QbCH4SNQIh"
      },
      "source": [
        "# Convert all inputs and labels into torch tensors, the required datatype \n",
        "# for our model.\n",
        "train_inputs = torch.tensor(train_inputs)\n",
        "validation_inputs = torch.tensor(validation_inputs)\n",
        "\n",
        "train_labels = torch.tensor(train_labels)\n",
        "validation_labels = torch.tensor(validation_labels)\n",
        "\n",
        "train_masks = torch.tensor(train_masks)\n",
        "validation_masks = torch.tensor(validation_masks)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2gP8uU5kNSkN"
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "\n",
        "# The DataLoader needs to know our batch size for training, so we specify it \n",
        "# here.\n",
        "# For fine-tuning BERT on a specific task, the authors recommend a batch size of\n",
        "# 16 or 32.\n",
        "\n",
        "batch_size = 16\n",
        "\n",
        "# Create the DataLoader for our training set.\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# Create the DataLoader for our validation set.\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5udS1Rq8NZQG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "538b620ed399444c801e4921578ae6ea",
            "501ed35045a04d3b9424c0f0f4cf0a18",
            "01bee5774aec4d1382f35a86a343075d",
            "4762123613844dd9a789cb92a61da15d",
            "b18174fd114b4bcb8ff3c621bff01400",
            "fb041bc090e6471695396f49fa02b871",
            "859d729812164ae7b80b3a578b722a63",
            "176bf078479944579654aa36e10a9137"
          ]
        },
        "outputId": "03d183f7-f406-4dfc-be59-72857bdb05c4"
      },
      "source": [
        "from transformers import RobertaForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
        "# linear classification layer on top. \n",
        "model = RobertaForSequenceClassification.from_pretrained(\n",
        "    \"Musixmatch/umberto-commoncrawl-cased-v1\", # Use the 12-layer BERT model, with an uncased vocab.\n",
        "    num_labels = 2, # The number of output labels--2 for binary classification.\n",
        "                    # You can increase this for multi-class tasks.   \n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        ")\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "538b620ed399444c801e4921578ae6ea",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=445031664.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RobertaForSequenceClassification(\n",
              "  (roberta): RobertaModel(\n",
              "    (embeddings): RobertaEmbeddings(\n",
              "      (word_embeddings): Embedding(32005, 768, padding_idx=1)\n",
              "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
              "      (token_type_embeddings): Embedding(1, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (classifier): RobertaClassificationHead(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p6Ib4A9VT6-H",
        "outputId": "8160ac31-0a06-4a58-b2ee-e9f475f3213d"
      },
      "source": [
        "# Get all of the model's parameters as a list of tuples.\n",
        "params = list(model.named_parameters())\n",
        "\n",
        "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
        "\n",
        "print('==== Embedding Layer ====\\n')\n",
        "\n",
        "for p in params[0:5]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== First Transformer ====\\n')\n",
        "\n",
        "for p in params[5:21]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== Output Layer ====\\n')\n",
        "\n",
        "for p in params[-4:]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The BERT model has 203 different named parameters.\n",
            "\n",
            "==== Embedding Layer ====\n",
            "\n",
            "roberta.embeddings.word_embeddings.weight               (32005, 768)\n",
            "roberta.embeddings.position_embeddings.weight             (514, 768)\n",
            "roberta.embeddings.token_type_embeddings.weight             (1, 768)\n",
            "roberta.embeddings.LayerNorm.weight                           (768,)\n",
            "roberta.embeddings.LayerNorm.bias                             (768,)\n",
            "\n",
            "==== First Transformer ====\n",
            "\n",
            "roberta.encoder.layer.0.attention.self.query.weight       (768, 768)\n",
            "roberta.encoder.layer.0.attention.self.query.bias             (768,)\n",
            "roberta.encoder.layer.0.attention.self.key.weight         (768, 768)\n",
            "roberta.encoder.layer.0.attention.self.key.bias               (768,)\n",
            "roberta.encoder.layer.0.attention.self.value.weight       (768, 768)\n",
            "roberta.encoder.layer.0.attention.self.value.bias             (768,)\n",
            "roberta.encoder.layer.0.attention.output.dense.weight     (768, 768)\n",
            "roberta.encoder.layer.0.attention.output.dense.bias           (768,)\n",
            "roberta.encoder.layer.0.attention.output.LayerNorm.weight       (768,)\n",
            "roberta.encoder.layer.0.attention.output.LayerNorm.bias       (768,)\n",
            "roberta.encoder.layer.0.intermediate.dense.weight        (3072, 768)\n",
            "roberta.encoder.layer.0.intermediate.dense.bias              (3072,)\n",
            "roberta.encoder.layer.0.output.dense.weight              (768, 3072)\n",
            "roberta.encoder.layer.0.output.dense.bias                     (768,)\n",
            "roberta.encoder.layer.0.output.LayerNorm.weight               (768,)\n",
            "roberta.encoder.layer.0.output.LayerNorm.bias                 (768,)\n",
            "\n",
            "==== Output Layer ====\n",
            "\n",
            "classifier.dense.weight                                   (768, 768)\n",
            "classifier.dense.bias                                         (768,)\n",
            "classifier.out_proj.weight                                  (2, 768)\n",
            "classifier.out_proj.bias                                        (2,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ouu1SA0GT_xn"
      },
      "source": [
        "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
        "# I believe the 'W' stands for 'Weight Decay fix\"\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 1e-5, # args.learning_rate - default is 5e-5, our notebook had 1e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQ5nWYMmUBr4"
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs (authors recommend between 2 and 4)\n",
        "epochs = 5\n",
        "\n",
        "# Total number of training steps is number of batches * number of epochs.\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7ej1o8SUNnA"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWgsP_FwUP9R"
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EDs88FBmUgAZ",
        "outputId": "86eacf5f-95c9-4340-9006-5c594c8b475c"
      },
      "source": [
        "import random\n",
        "\n",
        "\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "\n",
        "\n",
        "# Store the average loss after each epoch so we can plot them.\n",
        "loss_values = []\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_loss = 0\n",
        "    total_valid_loss = 0\n",
        "\n",
        "    # Put the model into training mode. Don't be mislead--the call to \n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because \n",
        "        # accumulating the gradients is \"convenient while training RNNs\". \n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()        \n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # This will return the loss (rather than the model output) because we\n",
        "        # have provided the `labels`.\n",
        "        # The documentation for this `model` function is here: \n",
        "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "        outputs = model(b_input_ids, \n",
        "                    token_type_ids=None, \n",
        "                    attention_mask=b_input_mask, \n",
        "                    labels=b_labels)\n",
        "        \n",
        "        # The call to `model` always returns a tuple, so we need to pull the \n",
        "        # loss value out of the tuple.\n",
        "        loss = outputs[0]\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value \n",
        "        # from the tensor.\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over the training data.\n",
        "    avg_train_loss = total_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Store the loss value for plotting the learning curve.\n",
        "    loss_values.append(avg_train_loss)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        # Add batch to GPU\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        \n",
        "        # Unpack the inputs from our dataloader\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        \n",
        "        # Telling the model not to compute or store gradients, saving memory and\n",
        "        # speeding up validation\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # This will return the logits rather than the loss because we have\n",
        "            # not provided labels.\n",
        "            # token_type_ids is the same as the \"segment ids\", which \n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            # The documentation for this `model` function is here: \n",
        "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "            outputs = model(b_input_ids, \n",
        "                            token_type_ids=None, \n",
        "                            attention_mask=b_input_mask,\n",
        "                            labels=b_labels)\n",
        "        \n",
        "        valid_loss = outputs[0]\n",
        "        total_valid_loss += valid_loss.item()\n",
        "        # Calculate the average loss over the training data.\n",
        "        avg_valid_loss = total_valid_loss / len(validation_dataloader)\n",
        "        \n",
        "        # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "        # values prior to applying an activation function like the softmax.\n",
        "        logits = outputs[1]\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "        \n",
        "        # Calculate the accuracy for this batch of test sentences.\n",
        "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "        \n",
        "        # Accumulate the total accuracy.\n",
        "        eval_accuracy += tmp_eval_accuracy\n",
        "\n",
        "        # Track the number of batches\n",
        "        nb_eval_steps += 1\n",
        "    # Report the final accuracy for this validation run.\n",
        "    print(\"  Average validation loss: {0:.2f}\".format(avg_valid_loss))\n",
        "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
        "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 5 ========\n",
            "Training...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/optimization.py:155: UserWarning: This overload of add_ is deprecated:\n",
            "\tadd_(Number alpha, Tensor other)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)\n",
            "  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch    40  of    225.    Elapsed: 0:00:14.\n",
            "  Batch    80  of    225.    Elapsed: 0:00:29.\n",
            "  Batch   120  of    225.    Elapsed: 0:00:43.\n",
            "  Batch   160  of    225.    Elapsed: 0:00:58.\n",
            "  Batch   200  of    225.    Elapsed: 0:01:13.\n",
            "\n",
            "  Average training loss: 0.43\n",
            "  Training epcoh took: 0:01:23\n",
            "\n",
            "Running Validation...\n",
            "  Average validation loss: 0.25\n",
            "  Accuracy: 0.91\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "======== Epoch 2 / 5 ========\n",
            "Training...\n",
            "  Batch    40  of    225.    Elapsed: 0:00:15.\n",
            "  Batch    80  of    225.    Elapsed: 0:00:31.\n",
            "  Batch   120  of    225.    Elapsed: 0:00:47.\n",
            "  Batch   160  of    225.    Elapsed: 0:01:03.\n",
            "  Batch   200  of    225.    Elapsed: 0:01:20.\n",
            "\n",
            "  Average training loss: 0.26\n",
            "  Training epcoh took: 0:01:30\n",
            "\n",
            "Running Validation...\n",
            "  Average validation loss: 0.21\n",
            "  Accuracy: 0.93\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "======== Epoch 3 / 5 ========\n",
            "Training...\n",
            "  Batch    40  of    225.    Elapsed: 0:00:16.\n",
            "  Batch    80  of    225.    Elapsed: 0:00:32.\n",
            "  Batch   120  of    225.    Elapsed: 0:00:48.\n",
            "  Batch   160  of    225.    Elapsed: 0:01:04.\n",
            "  Batch   200  of    225.    Elapsed: 0:01:20.\n",
            "\n",
            "  Average training loss: 0.20\n",
            "  Training epcoh took: 0:01:30\n",
            "\n",
            "Running Validation...\n",
            "  Average validation loss: 0.24\n",
            "  Accuracy: 0.92\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "======== Epoch 4 / 5 ========\n",
            "Training...\n",
            "  Batch    40  of    225.    Elapsed: 0:00:16.\n",
            "  Batch    80  of    225.    Elapsed: 0:00:32.\n",
            "  Batch   120  of    225.    Elapsed: 0:00:48.\n",
            "  Batch   160  of    225.    Elapsed: 0:01:04.\n",
            "  Batch   200  of    225.    Elapsed: 0:01:20.\n",
            "\n",
            "  Average training loss: 0.16\n",
            "  Training epcoh took: 0:01:30\n",
            "\n",
            "Running Validation...\n",
            "  Average validation loss: 0.24\n",
            "  Accuracy: 0.93\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "======== Epoch 5 / 5 ========\n",
            "Training...\n",
            "  Batch    40  of    225.    Elapsed: 0:00:16.\n",
            "  Batch    80  of    225.    Elapsed: 0:00:32.\n",
            "  Batch   120  of    225.    Elapsed: 0:00:48.\n",
            "  Batch   160  of    225.    Elapsed: 0:01:04.\n",
            "  Batch   200  of    225.    Elapsed: 0:01:20.\n",
            "\n",
            "  Average training loss: 0.13\n",
            "  Training epcoh took: 0:01:30\n",
            "\n",
            "Running Validation...\n",
            "  Average validation loss: 0.25\n",
            "  Accuracy: 0.92\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "Training complete!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "id": "RZw26IT7Wx1T",
        "outputId": "f533362d-013e-4289-d33f-ba8c9660b5c1"
      },
      "source": [
        "% matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(loss_values, 'b-o')\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tuT_E6MBTvJS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b82447f5-f606-4c9e-c1ec-1119e9dbabb1"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset into a pandas dataframe.\n",
        "df = pd.read_csv(source_folder + \"it_testing_labeled.tsv\", delimiter='\\t', header=0, names=['id', 'sentence', 'label', 'category', 'target'])\n",
        "\n",
        "# Report the number of sentences.\n",
        "print('Number of test sentences: {:,}\\n'.format(df.shape[0]))\n",
        "\n",
        "# Create sentence and label lists\n",
        "sentences = df.sentence.values\n",
        "labels = df.label.values\n",
        "\n",
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "    # `encode` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    encoded_sent = tokenizer.encode(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                   )\n",
        "    \n",
        "    input_ids.append(encoded_sent)\n",
        "\n",
        "# Pad our input tokens\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, \n",
        "                          dtype=\"long\", truncating=\"post\", padding=\"post\", value=1)\n",
        "\n",
        "# Create attention masks\n",
        "attention_masks = []\n",
        "\n",
        "# Create a mask of 1s for each token followed by 0s for padding\n",
        "for seq in input_ids:\n",
        "  seq_mask = [float(i>1) for i in seq]\n",
        "  attention_masks.append(seq_mask) \n",
        "\n",
        "# Convert to tensors.\n",
        "prediction_inputs = torch.tensor(input_ids)\n",
        "prediction_masks = torch.tensor(attention_masks)\n",
        "prediction_labels = torch.tensor(labels)\n",
        "\n",
        "# Set the batch size.  \n",
        "batch_size = 16\n",
        "\n",
        "# Create the DataLoader.\n",
        "prediction_data = TensorDataset(prediction_inputs, prediction_masks, prediction_labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of test sentences: 1,000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5jISlTgXXU0Q",
        "outputId": "18e86afa-3b7d-44a0-8b20-e610afb6773f"
      },
      "source": [
        "print('Predicting labels for {:,} test sentences...'.format(len(prediction_inputs)))\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "predictions , true_labels = [], []\n",
        "\n",
        "# Predict \n",
        "for batch in prediction_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  \n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  \n",
        "  # Telling the model not to compute or store gradients, saving memory and \n",
        "  # speeding up prediction\n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      outputs = model(b_input_ids, token_type_ids=None, \n",
        "                      attention_mask=b_input_mask)\n",
        "\n",
        "  logits = outputs[0]\n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  \n",
        "  # Store predictions and true labels\n",
        "  predictions.extend(logits)\n",
        "  true_labels.extend(label_ids)\n",
        "\n",
        "print('    DONE.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting labels for 1,000 test sentences...\n",
            "    DONE.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Np1hjf-rbNZs",
        "outputId": "d7eddc42-a9e7-4f64-bd50-5f1761bec99a"
      },
      "source": [
        "pred_flat = np.argmax(predictions, axis=1).flatten()\n",
        "\n",
        "def eval_accuracy(a, b):\n",
        "  true_pred = [j for i, j in zip(a, b) if i == j]\n",
        "  accuracy = len(true_pred)/len(a)\n",
        "  return accuracy\n",
        "\n",
        "print(eval_accuracy(true_labels, pred_flat))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.868\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mWcSJqecepe7",
        "outputId": "35654686-a85e-4cf0-b61c-4de702998336"
      },
      "source": [
        "# Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
        "# They can then be reloaded using `from_pretrained()`\n",
        "model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
        "model_to_save.save_pretrained(destination_folder)\n",
        "tokenizer.save_pretrained(destination_folder)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/content/drive/My Drive/ami_umberto2/sentencepiece.bpe.model',\n",
              " '/content/drive/My Drive/ami_umberto2/special_tokens_map.json',\n",
              " '/content/drive/My Drive/ami_umberto2/added_tokens.json')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "89bd9e2608fb4d988cce42a0eca2e550",
            "055d194d53444511acfc49b56372ee04",
            "b9fd8449660f482e92882b3cfe9be182",
            "2fe1f09c00f14adab1f9d822a968824a",
            "d00ea6d193354b2fac3555c5ab4db3a0",
            "3e0cf452ab7a44dfaca15ef6320f3008",
            "dbc8e881b4f848ae879e993c3f984982",
            "6f3d71d35c274b93b019341de2464612",
            "328a0d0301944ac09b2d324090030b6b",
            "92cdef78cf5b49de9453b751238133f7",
            "4080c5a6dd5a43f2916ce516f6719262",
            "be3a3499febc43a9b54b39e40e73d53f",
            "03c4f92441264f3f8c8d1a467d359381",
            "c0897c16347b428eaead9fa09f960c95",
            "b9c51f57a4df4e4fa94fc96d05715521",
            "6c16c474748e4fd9aa226b343922f7e5"
          ]
        },
        "id": "OjK0LO9NfEaB",
        "outputId": "3d1a2d8f-7c68-4ff7-f3ba-ec9b5acb6cb8"
      },
      "source": [
        "from transformers import RobertaForSequenceClassification, AutoTokenizer\n",
        "# Load a trained model and vocabulary that you have fine-tuned\n",
        "model = RobertaForSequenceClassification.from_pretrained(destination_folder)\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"Musixmatch/umberto-commoncrawl-cased-v1\")\n",
        "\n",
        "# Copy the model to the GPU.\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "89bd9e2608fb4d988cce42a0eca2e550",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=508.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "328a0d0301944ac09b2d324090030b6b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=793981.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RobertaForSequenceClassification(\n",
              "  (roberta): RobertaModel(\n",
              "    (embeddings): RobertaEmbeddings(\n",
              "      (word_embeddings): Embedding(32005, 768, padding_idx=1)\n",
              "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
              "      (token_type_embeddings): Embedding(1, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (classifier): RobertaClassificationHead(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xFkAutlv7Wz9"
      },
      "source": [
        "# Predictions on raw text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69Wu63S-2pMX"
      },
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "from scipy.special import softmax\n",
        "\n",
        "\n",
        "def classify(model, tokenizer, sentence):\n",
        "  attention_mask = []\n",
        "  input_ids = []\n",
        "  MAX_LEN=128\n",
        "  encoded_sent = tokenizer.encode(\n",
        "                        sentence,                      # Sentence to encode.\n",
        "                        add_special_tokens = True # Add '[CLS]' and '[SEP]'\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.\n",
        "  input_ids.append(encoded_sent)\n",
        "  input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", \n",
        "                          value=0, truncating=\"post\", padding=\"post\")\n",
        "\n",
        "  att_mask = [int(token_id > 0) for token_id in input_ids[0]]\n",
        "  attention_mask.append(att_mask)\n",
        "  input_ids = torch.tensor(input_ids[0], dtype=torch.long).unsqueeze(0)\n",
        "  attention_mask = torch.tensor(attention_mask[0], dtype=torch.long).unsqueeze(0)\n",
        "  input_ids = input_ids.to(device, dtype=torch.long)\n",
        "  attention_mask = attention_mask.to(device, dtype=torch.long)\n",
        "  predictions = []\n",
        "  model.eval()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    output = model(input_ids=input_ids,  attention_mask=attention_mask, labels=None)\n",
        "    logits = output[0].detach().cpu().numpy()\n",
        "    predictions.extend(logits)\n",
        "          \n",
        "  probability = softmax(predictions, axis=1)[0]\n",
        "  return probability"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ajuNImA3ej1",
        "outputId": "84c6d577-1391-4200-9a99-b4902668c965"
      },
      "source": [
        "sentence = \"@AsiaArgento @lauraboldrini Sei stata zitta per 20 anni! Ma di quale museruola parli? Potevi parlare prima. Sei patetica! ?\"\n",
        "print(classify(model, tokenizer, sentence))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.09773191 0.90226805]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}